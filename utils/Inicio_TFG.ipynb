{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Inicio_TFG.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"sCdUs9VUkg8L"},"source":["# Creación de clase imágenes"]},{"cell_type":"markdown","metadata":{"id":"LG_gpO1Ky3QH"},"source":["Si queremos crear una clase de datos particular: https://mlearninglab.com/2020/04/04/datasets-y-dataloader-en-pytorch/ o https://hackernoon.com/procesando-datos-para-deep-learning-datasets-visualizaciones-y-dataloaders-en-pytorch-hu1w36ly\n","\n","Las clases Dataset permiten instanciar objetos con el conjunto de datos que se van a cargar. PyTorch permite crear dos tipos distintos de datasets:\n","\n","* Map-style: Implementa los métodos getitem() and len() y representa un mapeo de claves/índices a valores del conjunto de datos. La clase Dataset es un ejemplo.\n","> * get_item() nos permite hacer \"indexing\", es decir que StarWarsDataSet[0] nos devuelva el primer elemento del dataset\n","\n","\n","* Iterable-style: Implementa el método iter() y representa un iterable sobre los datos. La clase IterableDataset es un ejemplo.\n"]},{"cell_type":"code","metadata":{"id":"QSLtj6JeEJpv"},"source":["from google.colab import drive\n"," \n","drive.mount('/content/drive') \n","data_dir = './drive/MyDrive/imagenes'\n","\n","\n","transform = transforms.Compose(\n","    [torchvision.transforms.ToPILImage(),\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VP20N1HUvtlE","executionInfo":{"status":"ok","timestamp":1617629590371,"user_tz":-120,"elapsed":4656,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}}},"source":["import torch\n","from torch.utils.data import Dataset"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ex0Fyi7_vs0F"},"source":["class StarWarsDataset(Dataset):\n","    def __init__(self, imgs, labels, transformaciones = None):\n","        self.imgs = imgs\n","        self.labels = labels\n","        self.transformaciones = transformaciones\n","\n","    def __len__(self):\n","        return len(self.imgs)\n","\n","    def __getitem__(self, idx):\n","        idx_img = self.imgs[idx]\n","        idx_lbl = self.labels[idx]\n","\n","        if self.transformaciones: # aplicacmos la transformacion (normalizar)\n","            idx_img = self.transformaciones(idx_img)\n","\n","            #creamos un diccionario que es lo que se devuelve\n","            muestra = {\"imagen\" : idx_img,\n","                      \"etiqueta\" : idx_lbl}\n","        return muestra"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u0M8f7pUA9QO","executionInfo":{"status":"ok","timestamp":1617625987364,"user_tz":-120,"elapsed":2693,"user":{"displayName":"Ángela Martínez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs54aizz7inUyiHZGy6wMscmXjAIi8Yg2P9yYGMQ=s64","userId":"17408159859815897792"}},"outputId":"b482a69e-e091-4bbf-f3f9-da8c6dd4bee6"},"source":["import tensorflow as tf\n","(x_train, y_train), (x_val, y_val) = tf.keras.datasets.mnist.load_data()\n","type(dataSet)\n","x_train\n","type(x_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"IHa1viqQv2Q7"},"source":["Podemos crear una instancia de nuestra nueva clase\n"]},{"cell_type":"code","metadata":{"id":"TUeQWPASv5ss"},"source":["dataset = NumbersDataset()\n","print(len(dataset))\n","print(dataset[100])\n","print(dataset[122:125])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TBuiKu0XwRsz"},"source":["La clase *torch.utils.data.DataLoader* es la clase principal para cargar los datos. \n","A esta clase se le pasa como argumento un objeto *Dataset*.\n","\n","Para usarla tenemos que crear una instancia de la clase *DataLoader* a la que pasamos el objeto dataset que hemos creado. Definimos un tamaño de batch de 10 y shuffle=False para que no se cambie el orden de los datos en cada epoch (recorrido completo de los datos). \n"]},{"cell_type":"code","metadata":{"id":"ShmEzmLfwSVl"},"source":["batch_size=10\n","\n","train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n","for i, (numbers, labels) in enumerate(train_loader):\n","  if  i<11:\n","    print('Batch number %d'%(i+1))\n","    print(numbers, labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8WyeN7gtkoIr"},"source":["# Creación modelo"]},{"cell_type":"markdown","metadata":{"id":"MxjHF4BQSz7O"},"source":["## Importación de datos"]},{"cell_type":"code","metadata":{"id":"gv2LfF6VS4gV","executionInfo":{"status":"ok","timestamp":1617630607303,"user_tz":-120,"elapsed":873,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}}},"source":["import os\n","import torch\n","import torchvision\n","from torch.utils.data import random_split\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import ToTensor"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kmlSxtcz8EWj"},"source":["(https://www.adictosaltrabajo.com/2019/06/04/google-colab-python-y-machine-learning-en-la-nube/) \n","Para importar los datos de google drive, no tenemos que meter en el enlace que aparece debajo, tenemos que aceptar y copiar la conytraseña que nos sale\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BFr29Mn8D9c","executionInfo":{"status":"ok","timestamp":1617630628245,"user_tz":-120,"elapsed":19547,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}},"outputId":"bb0eb74d-07e9-4995-9bd8-6b44491f3594"},"source":["from google.colab import drive\n"," \n","drive.mount('/content/drive') "],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"abe_ZdljITeZ"},"source":["Ya tenemos los datos importados, vemos las carpetas que hay con las fotos, cada carpeta se convertirá en un etiqueta 0=dibujos2D 1=dibujos3D y por último 2=personas"]},{"cell_type":"code","metadata":{"id":"sr5q5Ld_TCSt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617630631526,"user_tz":-120,"elapsed":846,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}},"outputId":"a7b81474-ee01-4a58-84fc-ed0b385443b0"},"source":["data_dir = './drive/MyDrive/imagenes'\n","\n","print(os.listdir(data_dir))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["['dibujos2D', 'dibujos3D', 'personas']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c3rCcPd0B-fM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617630634943,"user_tz":-120,"elapsed":1434,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}},"outputId":"fab45a11-d2b2-4f3b-ca37-d3d1c98c8db1"},"source":["dataSet = ImageFolder(data_dir, transform=ToTensor())\n","print(dataSet.classes)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['dibujos2D', 'dibujos3D', 'personas']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RMKHLN8O2fk","executionInfo":{"status":"ok","timestamp":1617630642318,"user_tz":-120,"elapsed":2064,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}},"outputId":"c58a5437-7c7f-4b65-82d0-b2f74f517f79"},"source":["img, label = dataSet[78]\n","print(img.shape, label)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["torch.Size([3, 1634, 3840]) 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sDt1hG9ZSyI7"},"source":["Creamos dataLoader"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHh7qRizS0hS","executionInfo":{"status":"ok","timestamp":1617630643986,"user_tz":-120,"elapsed":1428,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}},"outputId":"f70d6f4c-d69a-4011-8450-1e1e4a7051a4"},"source":["from torch.utils.data.dataloader import DataLoader\n","\n","batch_size=128\n","\n","train_dl = DataLoader(dataSet, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n","#val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Q41ZTHxBfOVD"},"source":["## Clase base\n","Empezamos a crear nuestro modelo"]},{"cell_type":"code","metadata":{"id":"uOlimiJlfNzA","executionInfo":{"status":"ok","timestamp":1617630648108,"user_tz":-120,"elapsed":856,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}}},"source":["import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"GT3jU7ezfvi5","executionInfo":{"status":"ok","timestamp":1617630649936,"user_tz":-120,"elapsed":871,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}}},"source":["class ImageClassificationBase(nn.Module):\n","    def training_step(self, batch):\n","        images, labels = batch \n","        out = self(images)                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","    \n","    def validation_step(self, batch):\n","        images, labels = batch \n","        out = self(images)                    # Generate predictions\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)           # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","        \n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","    \n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n","        \n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"weiPsb8vk4fq"},"source":["## Modelo StarWars"]},{"cell_type":"code","metadata":{"id":"OVbqNfFnf19h","executionInfo":{"status":"ok","timestamp":1617630805139,"user_tz":-120,"elapsed":860,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}}},"source":["class StarWarsCnnModel(ImageClassificationBase):\n","    def __init__(self):\n","        super().__init__()\n","        self.network = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n","\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n","\n","            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n","\n","            nn.Flatten(), \n","            nn.Linear(256*4*4, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10))\n","        \n","    def forward(self, xb):\n","        return self.network(xb)\n","\n","model = StarWarsCnnModel()"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"A6soWtC3mF1X"},"source":["for images, labels in train_dl:\n","    print('images.shape:', images.shape)\n","    out = model(images)\n","    print('out.shape:', out.shape)\n","    print('out[0]:', out[0])\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8HXvWg8ymHnq"},"source":["## Entrenar usando GPU\n"]},{"cell_type":"markdown","metadata":{"id":"9hctOf-9lL4C"},"source":["### Creación funciones auxiliares"]},{"cell_type":"code","metadata":{"id":"H1gtpwEDmJpK","executionInfo":{"status":"ok","timestamp":1617630708179,"user_tz":-120,"elapsed":998,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}}},"source":["def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","    \n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jOyzciu6lRJ6"},"source":["### Entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"H6JS46aAUCSB"},"source":["DEfinimos funciones para entrenar"]},{"cell_type":"code","metadata":{"id":"HZtNkKXaUBGJ","executionInfo":{"status":"ok","timestamp":1617630989019,"user_tz":-120,"elapsed":884,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}}},"source":["@torch.no_grad()\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","\n","def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n","    history = []\n","    optimizer = opt_func(model.parameters(), lr)\n","    for epoch in range(epochs):\n","        # Training Phase \n","        model.train()\n","        train_losses = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        # Validation phase\n","        #result = evaluate(model, val_loader)\n","        #result['train_loss'] = torch.stack(train_losses).mean().item()\n","        #model.epoch_end(epoch, result)\n","        #history.append(result)\n","    return train_losses"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"skX-ZSBTUE86"},"source":["Movemos los datos a la memoria"]},{"cell_type":"code","metadata":{"id":"nDoT08UvmN4T","executionInfo":{"status":"ok","timestamp":1617630991839,"user_tz":-120,"elapsed":1057,"user":{"displayName":"Angela Martinez","photoUrl":"","userId":"07148972717248888383"}}},"source":["device = get_default_device()\n","train_dl = DeviceDataLoader(train_dl, device) # podemos poner shuffle = True\n","#val_dl = DeviceDataLoader(val_dl, device)\n","to_device(model, device);"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bw1D7XspUJB8"},"source":["Comenzamos el entrenamiento"]},{"cell_type":"code","metadata":{"id":"HJvPrKsAUL0p"},"source":["num_epochs = 2\n","lr = 0.001\n","opt_func = torch.optim.Adam\n","\n","history = fit(num_epochs, lr, model, train_dl, train_dl, opt_func)\n","history"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ugpQ4AB0ke1D"},"source":[""]}]}